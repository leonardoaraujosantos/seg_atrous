{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Segmentation with Atrous Convolution\n",
    "\n",
    "#### Loss\n",
    "This project will use BSE Loss and Dice loss\n",
    "\n",
    "#### Metrics\n",
    "![alt text](./imgs_doc/metrics.png \"Title\")\n",
    "\n",
    "#### References\n",
    "* https://arxiv.org/pdf/1709.00179.pdf\n",
    "* https://medium.com/beyondminds/a-simple-guide-to-semantic-segmentation-effcf83e7e54\n",
    "* https://medium.com/dair-ai/medical-imaging-analysis-mri-cnn-pytorch-4877e64e7303\n",
    "* https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7\n",
    "* https://github.com/kevinzakka/pytorch-goodies/blob/master/losses.py\n",
    "* https://arxiv.org/pdf/1702.03275.pdf\n",
    "* https://medium.com/syncedreview/facebook-ai-proposes-group-normalization-alternative-to-batch-normalization-fb0699bffae7\n",
    "* https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
    "* https://github.com/martinkersner/py_img_seg_eval\n",
    "* https://medicaltorch.readthedocs.io/en/stable/\n",
    "* https://arxiv.org/pdf/1702.05659.pdf\n",
    "* https://medium.com/@dmitrijtichonov/debunking-loss-functions-in-deep-learning-4b9abc4c8d4c\n",
    "* https://github.com/meetshah1995/pytorch-semseg\n",
    "* https://discuss.pytorch.org/t/leaf-variable-has-been-moved-into-the-graph-interior/18679/9\n",
    "* https://github.com/EKami/carvana-challenge/tree/original_unet\n",
    "* https://imgaug.readthedocs.io/en/latest/source/installation.html\n",
    "* https://medium.com/earthcube-stories/techsecret-how-to-use-deep-learning-on-satellite-imagery-episode-1-playing-with-the-loss-8fc05c90a63a\n",
    "* https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47\n",
    "\n",
    "#### Andrew Ng on Accuracy/Precision/Recall\n",
    "Accuracy it's not important if your dataset is imbalanced (Skewed), for example if your model say 100% of time that someone has no cancer, it will be really accurate, like 99.999% but it's Recall will be zero. \n",
    "* https://www.youtube.com/watch?v=k1JGvqr56Yk&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=66\n",
    "* https://www.youtube.com/watch?v=wGw6R8AbcuI\n",
    "* https://www.youtube.com/watch?v=W5meQnGACGo\n",
    "\n",
    "#### Distributed Training Pytorch\n",
    "* https://pytorch.org/tutorials/intermediate/dist_tuto.html\n",
    "* https://pytorch.org/tutorials/intermediate/ddp_tutorial.html\n",
    "* https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html\n",
    "* https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html\n",
    "* https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Number of GPUs Available: 8\n"
     ]
    }
   ],
   "source": [
    "import sat_utils\n",
    "import seg_loss\n",
    "import seg_metrics\n",
    "import seg_models\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pytorch stuff\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as utils\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Warm-Up Scheduler\n",
    "# https://github.com/ildoonet/pytorch-gradual-warmup-lr\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "# Library for augmentations on batch of numpy/tensors\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "print('Device:', device)\n",
    "num_gpu = torch.cuda.device_count()\n",
    "print('Number of GPUs Available:', num_gpu)\n",
    "\n",
    "lr=0.06521 #0.001 0.0001-(Good with Dice, 0.007 training)\n",
    "warm_up_epochs = 40\n",
    "l2_norm=0.0000001\n",
    "gamma=0.1\n",
    "batch_size = 128 #32 #20\n",
    "num_epochs = 500\n",
    "step_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data from pickle (Bad not scalable) and create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_t: (2038, 3, 76, 76)\n",
      "Y_t: (2038, 3, 76, 76)\n",
      "X_v: (227, 3, 76, 76)\n",
      "Y_v: (227, 3, 76, 76)\n"
     ]
    }
   ],
   "source": [
    "X = sat_utils.read_pickle_data('./data/input.pickle')\n",
    "Y = sat_utils.read_pickle_data('./data/label.pickle')\n",
    "\n",
    "# Convert dictionaries to numpy array\n",
    "X = np.stack([sat_utils.get_rgb(x) for x in X.values()])\n",
    "Y = np.stack([(x/255.0) for x in Y.values()])\n",
    "\n",
    "# Split train/validation\n",
    "X_t, X_v, Y_t, Y_v = train_test_split(X, Y, test_size=1/10, random_state=42)\n",
    "print('X_t:', X_t.shape)\n",
    "print('Y_t:', Y_t.shape)\n",
    "print('X_v:', X_v.shape)\n",
    "print('Y_v:', Y_v.shape)\n",
    "\n",
    "# Changes on label for Cross-Entropy (3 classes all mixed on the same image, N,W,H)\n",
    "# Changes on label for BCEWithLogitsLoss (3 classes on 3 Channels, N,C,W,H)\n",
    "tensor_x_t = torch.Tensor(X_t)\n",
    "tensor_y_t = torch.Tensor(Y_t)\n",
    "tensor_x_v = torch.Tensor(X_v)\n",
    "tensor_y_v = torch.Tensor(Y_v)\n",
    "\n",
    "# Define some augmentations\n",
    "seq_augm = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.Flipud(0.5), # vertically flip 50% of the images\n",
    "    #iaa.Affine(rotate=(-10, 10)), # Rotate the images\n",
    "])\n",
    "\n",
    "dataset_train = utils.TensorDataset(tensor_x_t,tensor_y_t)\n",
    "dataset_val = utils.TensorDataset(tensor_x_v,tensor_y_v)\n",
    "dataloader_train = utils.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = utils.DataLoader(dataset_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([2038, 3, 76, 76])\n",
      "Label: torch.Size([2038, 3, 76, 76])\n",
      "num_classes: 3\n",
      "Max val on label: 1.0\n",
      "Min val on label: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Input:',tensor_x_t.shape)\n",
    "print('Label:',tensor_y_t.shape)\n",
    "num_classes = tensor_y_t.shape[1]\n",
    "batch_val = tensor_y_v.shape[0]\n",
    "#num_classes = 4\n",
    "print('num_classes:', num_classes)\n",
    "print('Max val on label:', torch.max(tensor_y_t).item())\n",
    "print('Min val on label:', torch.min(tensor_y_t).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = seg_models.AtrousSeg(num_classes=num_classes, num_channels=tensor_x_t.shape[1])\n",
    "#resp = model(torch.rand(1, 8, 76, 76))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Tensorboard Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anaconda3/lib/python3.7/site-packages/torch/onnx/symbolic.py:173: UserWarning: ONNX export failed on upsample_bilinear2d because align_corners == True not supported\n",
      "  warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")\n"
     ]
    }
   ],
   "source": [
    "#writer = SummaryWriter('./logs')\n",
    "# Default directory \"runs\"\n",
    "writer = SummaryWriter()\n",
    "dummy_x = torch.rand(1, tensor_x_t.shape[1], 76, 76)\n",
    "writer.add_graph(model, dummy_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribute model on available GPUs\n",
    "On this case we're using DataParallel mode. It will copy the same model and split the batch between multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 8 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AtrousSeg(\n",
       "    (model): Sequential(\n",
       "      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "      (8): ReLU()\n",
       "      (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
       "      (11): ReLU()\n",
       "      (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(3, 3))\n",
       "      (14): ReLU()\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(3, 3))\n",
       "      (17): ReLU()\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(3, 3))\n",
       "      (20): ReLU()\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(3, 3))\n",
       "      (23): ReLU()\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(3, 3))\n",
       "      (26): ReLU()\n",
       "      (27): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (28): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(3, 3))\n",
       "      (29): ReLU()\n",
       "      (30): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (31): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(2, 2))\n",
       "      (32): ReLU()\n",
       "      (33): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (34): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(2, 2))\n",
       "      (35): ReLU()\n",
       "      (36): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (37): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (38): ReLU()\n",
       "      (39): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (40): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): ReLU()\n",
       "      (42): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (43): Conv2d(256, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1), dilation=(3, 3))\n",
       "      (44): ReLU()\n",
       "      (45): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (46): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (47): ReLU()\n",
       "      (48): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (49): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (50): UpsamplingBilinear2d(size=(76, 76), mode=bilinear)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if num_gpu > 1:\n",
    "    print(\"Let's use\", num_gpu, \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Losses and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification losses will have predictions on the format (batch, n_class, 12, 12)\n",
    "# and labels (batch, rows, cols) with values related to indexes of class\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Regularization losses accept any logits on format (batch, channels, rows, cols) \n",
    "#for both prediction and label\n",
    "#loss_fn = nn.MSELoss()\n",
    "#loss_fn = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_norm)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "# Warmup optimizer (warm first for 10 epochs)\n",
    "# Decrease learning rate if some metric doesnt change for \"patience\" epochs\n",
    "scheduler_plateau = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=4, verbose=True)\n",
    "#scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=10, total_epoch=warm_up_epochs, after_scheduler=exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 13/500 [11:19<6:49:52, 50.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    12: reducing learning rate of group 0 to 6.5210e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 18/500 [15:28<6:45:02, 50.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    17: reducing learning rate of group 0 to 6.5210e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 25/500 [21:10<6:28:14, 49.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    24: reducing learning rate of group 0 to 6.5210e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 29/500 [24:27<6:27:37, 49.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    28: reducing learning rate of group 0 to 6.5210e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 33/500 [27:45<6:26:56, 49.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    32: reducing learning rate of group 0 to 6.5210e-07.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 37/500 [31:01<6:21:26, 49.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    36: reducing learning rate of group 0 to 6.5210e-08.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 41/500 [34:16<6:13:07, 48.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    40: reducing learning rate of group 0 to 6.5210e-09.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 45/500 [37:34<6:11:35, 49.00s/it]"
     ]
    }
   ],
   "source": [
    "iteration_count = 0\n",
    "iteration_count_val = 0\n",
    "# For all epochs\n",
    "for epoch in tqdm(range(num_epochs), desc='Training'):\n",
    "    # Train step\n",
    "    model.train()    \n",
    "    running_loss = 0.0\n",
    "    # For all elements on the training set\n",
    "    for i, (imgs, labels) in enumerate(dataloader_train):\n",
    "        # Do augmentations the augmentation library expect numpy arrays on format Batch x Row x Cols x Channels\n",
    "        imgs_aug, labels_aug = seq_augm(images=np.moveaxis(imgs.numpy(),1,3), heatmaps=np.moveaxis(labels.numpy(),1,3))\n",
    "        \n",
    "        # Move axis back and convert back to tensor\n",
    "        imgs = torch.from_numpy(np.moveaxis(imgs_aug,3,1))\n",
    "        labels = torch.from_numpy(np.moveaxis(labels_aug,3,1))\n",
    "        \n",
    "        # Send inputs/labels to GPU                \n",
    "        labels = labels.to(device)\n",
    "        imgs = imgs.to(device)                \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        \n",
    "        #loss_dice = dice_loss(outputs, labels)\n",
    "        iou_value = seg_loss.iou_loss(outputs, labels)\n",
    "        dice_value  = seg_loss.dice_loss(outputs, labels)\n",
    "        criterion = loss_fn(outputs, labels)\n",
    "        #print(type(dice_val))\n",
    "        #loss = loss_fn(outputs, labels) + (1000*dice_val)\n",
    "        #loss = criterion# + (1000*dice_value)\n",
    "        #loss = iou_value\n",
    "        #loss = dice_value\n",
    "        loss = criterion + dice_value\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar('loss/', loss.item(), iteration_count)\n",
    "        writer.add_scalar('base_loss/', criterion.item(), iteration_count)\n",
    "        writer.add_scalar('iou_loss/', iou_value.item(), iteration_count)\n",
    "        writer.add_scalar('dice_loss/', dice_value.item(), iteration_count)\n",
    "        iteration_count+=1        \n",
    "    \n",
    "    # Print Finished epoch\n",
    "    \n",
    "    # Get current learning rate (To display on Tensorboard)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        curr_learning_rate = param_group['lr']\n",
    "        writer.add_scalar('learning_rate/', curr_learning_rate, epoch)\n",
    "    \n",
    "    # Send images from training to tensorboard\n",
    "    out_norm = sat_utils.img_minmax_norm_torch(outputs)\n",
    "    labels_norm = sat_utils.img_minmax_norm_torch(labels)\n",
    "    imgs_norm = sat_utils.img_minmax_norm_torch(imgs)\n",
    "    writer.add_images('img_t', imgs_norm, epoch)\n",
    "    writer.add_images('out_mask_t', out_norm[:, 0, :, :].unsqueeze(1), epoch)    \n",
    "    writer.add_images('out_sep_t', out_norm[:, 1, :, :].unsqueeze(1), epoch)\n",
    "    writer.add_images('out_border_t', out_norm[:, 2, :, :].unsqueeze(1), epoch)\n",
    "    writer.add_images('label_mask_t', labels_norm[:, 0, :, :].unsqueeze(1), epoch)\n",
    "    writer.add_images('label_sep_t', labels_norm[:, 1, :, :].unsqueeze(1), epoch)\n",
    "    writer.add_images('label_border_t', labels_norm[:, 2, :, :].unsqueeze(1), epoch)\n",
    "    \n",
    "    # Run Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, labels) in enumerate(dataloader_val):\n",
    "            # Send inputs/labels to GPU                \n",
    "            labels = labels.to(device)\n",
    "            imgs = imgs.to(device)                \n",
    "            outputs = model(imgs)\n",
    "            iou_value = seg_metrics.iou(outputs, labels)\n",
    "            dice_value = seg_metrics.dice(outputs, labels)\n",
    "            writer.add_scalar('iou_val/', iou_value.item(), iteration_count_val)\n",
    "            writer.add_scalar('dice_val/', dice_value.item(), iteration_count_val)\n",
    "            iteration_count_val += 1\n",
    "    \n",
    "    # Send images from validation to tensorboard\n",
    "    out_norm = sat_utils.img_minmax_norm_torch(outputs)\n",
    "    labels_norm = sat_utils.img_minmax_norm_torch(labels)\n",
    "    imgs_norm = sat_utils.img_minmax_norm_torch(imgs)\n",
    "    writer.add_images('img_v', imgs_norm, epoch)\n",
    "    writer.add_images('out_mask_v', out_norm[:, 0, :, :].unsqueeze(1), epoch)    \n",
    "    writer.add_images('label_mask_v', labels_norm[:, 0, :, :].unsqueeze(1), epoch)\n",
    "    \n",
    "    # Save Model\n",
    "    torch.save(model, './model_save/model_'+str(epoch)+'.cpkt')\n",
    "    \n",
    "    # Step learning rate Decay\n",
    "    #exp_lr_scheduler.step(epoch)\n",
    "    #scheduler_warmup.step()\n",
    "    scheduler_plateau.step(running_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Specific Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./model_save/model_499.cpkt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(idx_img=widgets.IntSlider(min=0,max=tensor_x_t.shape[0]-1), th_mask_iteractive=widgets.IntSlider(min=0,max=100), use_threshold = False)\n",
    "def testModel(idx_img):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        img = tensor_x_t[idx_img].unsqueeze(0).to(device)\n",
    "        pred = model(img)\n",
    "        label = tensor_y_t[idx_img].to(device)\n",
    "        dice_value = seg_metrics.dice(pred, label.unsqueeze(0))\n",
    "        iou_value = seg_metrics.iou(pred, label.unsqueeze(0))\n",
    "        dice_loss_value = seg_loss.dice_loss(pred, label.unsqueeze(0))\n",
    "        iou_loss_value = seg_loss.iou_loss(pred, label.unsqueeze(0))\n",
    "        \n",
    "    img_numpy = img.cpu().squeeze().numpy()\n",
    "    img_numpy = sat_utils.img_minmax_norm(img_numpy)\n",
    "    img_numpy_m = np.moveaxis(img_numpy, 0, 2)\n",
    "    \n",
    "    pred_numpy = pred.cpu().squeeze().numpy()\n",
    "    # Test\n",
    "    pred_numpy_sig = F.sigmoid(pred).cpu().squeeze().numpy()\n",
    "    label_numpy = tensor_y_t[idx_img].squeeze().numpy()   \n",
    "    img_numpy = sat_utils.img_minmax_norm(img_numpy)\n",
    "    \n",
    "    print('Dice Val:', dice_value)\n",
    "    print('IoU Val:', iou_value)\n",
    "    print('Dice Loss:', dice_loss_value)\n",
    "    print('IoU Loss:', iou_loss_value)\n",
    "    \n",
    "    if num_classes > 1:\n",
    "        # Merge Mask and Border\n",
    "        mask_border = pred_numpy[0,:,:] - pred_numpy[1,:,:]\n",
    "        \n",
    "        f, axarr = plt.subplots(1, 5, figsize=(15,15))\n",
    "        axarr[0].imshow(img_numpy_m) #4 With 8 channels\n",
    "        axarr[0].title.set_text('Original')\n",
    "        axarr[1].imshow(pred_numpy[0,:,:])\n",
    "        axarr[1].title.set_text('Prediction Mask')\n",
    "        axarr[2].imshow(pred_numpy[1,:,:])\n",
    "        axarr[2].title.set_text('Prediction Border')\n",
    "        axarr[3].imshow(mask_border)\n",
    "        axarr[3].title.set_text('Subtracted')\n",
    "        axarr[4].imshow(label_numpy[0,:,:])\n",
    "        axarr[4].title.set_text('Label')\n",
    "    else:\n",
    "        f, axarr = plt.subplots(1, 3, figsize=(15,15))\n",
    "        axarr[0].imshow(img_numpy[0,:,:]) #4 With 8 channels\n",
    "        axarr[0].title.set_text('Original')\n",
    "        axarr[1].imshow(pred_numpy[:,:])\n",
    "        axarr[1].title.set_text('Prediction Mask')\n",
    "        axarr[2].imshow(label_numpy)\n",
    "        axarr[2].title.set_text('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
