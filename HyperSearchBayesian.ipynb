{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search\n",
    "Use Bayesian optimization to find (learning-rate and momentum). The advantage of bayesian optimization compared to grid/random search is that those methods are less sample efficient compared to bayesian optimization.\n",
    "\n",
    "#### References\n",
    "* https://en.wikipedia.org/wiki/Bayesian_optimization\n",
    "* https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f\n",
    "* https://ax.dev\n",
    "* https://ax.dev/tutorials/tune_cnn.html\n",
    "* https://botorch.org\n",
    "* https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf\n",
    "* http://krasserm.github.io/2018/03/21/bayesian-optimization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/mnt/anaconda3/lib/python3.7/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard.summary.writer'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6063f58a8ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/anaconda3/lib/python3.7/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     raise ImportError('TensorBoard logging requires TensorBoard with Python summary writer installed. '\n\u001b[0m\u001b[1;32m      5\u001b[0m                       'This should be available in 1.14 or above.')\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Dict, Tuple\n",
    "import torch.utils.data as utils\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Library for augmentations on batch of numpy/tensors\n",
    "from imgaug import augmenters as iaa\n",
    "import lamb as lb\n",
    "\n",
    "import sat_utils\n",
    "import seg_loss\n",
    "import seg_metrics\n",
    "import seg_models\n",
    "\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "from ax.utils.tutorials.cnn_utils import load_mnist, train, evaluate\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "print('Device:', device)\n",
    "num_gpu = torch.cuda.device_count()\n",
    "print('Number of GPUs Available:', num_gpu)\n",
    "\n",
    "lr=1e-6 #0.001 0.0001-(Good with Dice, 0.007 training)\n",
    "l2_norm=0.0000001\n",
    "gamma=0.1\n",
    "batch_size = 600 #600 #32 #20\n",
    "num_epochs = 50\n",
    "step_size = 200\n",
    "\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from pickle (Bad not scalable) and create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_t: (2038, 3, 76, 76)\n",
      "Y_t: (2038, 2, 76, 76)\n",
      "X_v: (227, 3, 76, 76)\n",
      "Y_v: (227, 2, 76, 76)\n"
     ]
    }
   ],
   "source": [
    "X = sat_utils.read_pickle_data('./data/input.pickle')\n",
    "Y = sat_utils.read_pickle_data('./data/label.pickle')\n",
    "\n",
    "# Convert dictionaries to numpy array\n",
    "X = np.stack([sat_utils.get_rgb(x) for x in X.values()])\n",
    "#X = np.stack([sat_utils.get_rgbi(x) for x in X.values()])\n",
    "Y = np.stack([(x/255.0) for x in Y.values()])\n",
    "# Select only mask and between buildings\n",
    "Y = np.stack([Y[:, 0, :, :], Y[:, 1, :, :]], axis=1)\n",
    "\n",
    "# Split train/validation\n",
    "X_t, X_v, Y_t, Y_v = train_test_split(X, Y, test_size=1/10, random_state=42)\n",
    "print('X_t:', X_t.shape)\n",
    "print('Y_t:', Y_t.shape)\n",
    "print('X_v:', X_v.shape)\n",
    "print('Y_v:', Y_v.shape)\n",
    "\n",
    "# Changes on label for Cross-Entropy (3 classes all mixed on the same image, N,W,H)\n",
    "# Changes on label for BCEWithLogitsLoss (3 classes on 3 Channels, N,C,W,H)\n",
    "tensor_x_t = torch.Tensor(X_t)\n",
    "tensor_y_t = torch.Tensor(Y_t)\n",
    "tensor_x_v = torch.Tensor(X_v)\n",
    "tensor_y_v = torch.Tensor(Y_v)\n",
    "\n",
    "# Define some augmentations\n",
    "seq_augm = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.Flipud(0.5), # vertically flip 50% of the images\n",
    "    #iaa.Affine(rotate=(-10, 10)), # Rotate the images\n",
    "])\n",
    "\n",
    "dataset_train = utils.TensorDataset(tensor_x_t,tensor_y_t)\n",
    "dataset_val = utils.TensorDataset(tensor_x_v,tensor_y_v)\n",
    "dataloader_train = utils.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = utils.DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_classes = tensor_y_t.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f38fae44be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(Y[2000,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f38fadb89e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Y[2000,1,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Train Function\n",
    "Train the model for one epoch given:\n",
    "* Train loader\n",
    "* Parameters\n",
    "* Validation loader (Just to debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader: DataLoader, val_loader: DataLoader, parameters: Dict[str, float], dtype: torch.dtype, device: torch.device) -> nn.Module:\n",
    "    # Start Tensorboard interface\n",
    "    global writer\n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    # Initialize Model and optimizer\n",
    "    model = seg_models.AtrousSeg(num_classes=num_classes, num_channels=tensor_x_t.shape[1])\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=parameters.get(\"lr\", 0.001), momentum=parameters.get(\"momentum\", 0.9))\n",
    "    base_lr = parameters.get(\"lr\", 0.001)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=base_lr, weight_decay=l2_norm)\n",
    "    #optimizer = lb.Lamb(model.parameters(), lr=base_lr, weight_decay=0.01, betas=(.9, .99), adam=True)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Decrease learning rate if some metric doesnt change for \"patience\" epochs\n",
    "    scheduler_plateau = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=4, verbose=False)\n",
    "    \n",
    "    lw_bce = parameters.get(\"loss_weight_bce\", 1.0)\n",
    "    lw_iou = parameters.get(\"loss_weight_iou\", 1.0)\n",
    "    lw_dice = parameters.get(\"loss_weight_dice\", 1.0)\n",
    "    # Print parameters of loss weight\n",
    "    writer.add_scalar('bce_weight/', lw_bce, 0)\n",
    "    writer.add_scalar('iou_weight/', lw_iou, 0)\n",
    "    writer.add_scalar('dice_weight/', lw_dice, 0)\n",
    "    writer.add_scalar('base_lr/', base_lr, 0)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # Train Network\n",
    "    iteration_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for (imgs, labels) in train_loader:\n",
    "\n",
    "            # Do augmentations the augmentation library expect numpy arrays on format Batch x Row x Cols x Channels\n",
    "            imgs_aug, labels_aug = seq_augm(images=np.moveaxis(imgs.numpy(),1,3), heatmaps=np.moveaxis(labels.numpy(),1,3))\n",
    "\n",
    "            # Move axis back and convert back to tensor\n",
    "            imgs = torch.from_numpy(np.moveaxis(imgs_aug,3,1))\n",
    "            labels = torch.from_numpy(np.moveaxis(labels_aug,3,1))\n",
    "\n",
    "            # Send inputs/labels to GPU                \n",
    "            labels = labels.to(device)\n",
    "            imgs = imgs.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(imgs)\n",
    "            dice_value  = seg_loss.dice_loss(outputs, labels)\n",
    "            ioU_value  = seg_loss.iou_loss(outputs, labels)\n",
    "            bce_value = criterion(outputs, labels)\n",
    "            loss = (lw_bce*bce_value) + (lw_dice*dice_value) + (lw_iou*ioU_value)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar('loss/', loss.item(), iteration_count)\n",
    "            writer.add_scalar('dice_loss/', dice_value.item(), iteration_count)\n",
    "            iteration_count+=1  \n",
    "        \n",
    "        # Finished epoch\n",
    "        # Get current learning rate (To display on Tensorboard)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            curr_learning_rate = param_group['lr']\n",
    "            writer.add_scalar('learning_rate/', curr_learning_rate, epoch)\n",
    "        \n",
    "        # Evaluate model after epoch\n",
    "        model.eval()\n",
    "        list_iou_val = []\n",
    "        with torch.no_grad():\n",
    "            for (imgs, labels) in val_loader:\n",
    "                # Send inputs/labels to GPU                \n",
    "                labels = labels.to(device)\n",
    "                imgs = imgs.to(device)                \n",
    "                outputs = model(imgs)\n",
    "                iou_value = seg_metrics.iou(outputs, labels)\n",
    "                # Append IoU val for each batch of of data from validation\n",
    "                list_iou_val.append(iou_value.item())\n",
    "\n",
    "        # Report IoU mean \n",
    "        iou_val = np.mean(list_iou_val)\n",
    "        writer.add_scalar('iou_val_run/', np.mean(list_iou_val), epoch)\n",
    "        \n",
    "        # Step learning rate scheduler\n",
    "        scheduler_plateau.step(running_loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Evaluation Function\n",
    "Evaluate the model given:\n",
    "* Some Model\n",
    "* Data Loader\n",
    "This function will run after the end of the train trial, which basically will guide the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, val_loader: DataLoader, dtype: torch.dtype, device: torch.device) -> float:    \n",
    "    global writer \n",
    "    model.eval()\n",
    "    list_iou_val = []\n",
    "    with torch.no_grad():\n",
    "        for (imgs, labels) in val_loader:\n",
    "            # Send inputs/labels to GPU                \n",
    "            labels = labels.to(device)\n",
    "            imgs = imgs.to(device)                \n",
    "            outputs = model(imgs)\n",
    "            iou_value = seg_metrics.iou(outputs, labels)\n",
    "            # Append IoU val for each batch of of data from validation\n",
    "            list_iou_val.append(iou_value.item())\n",
    "    \n",
    "    # Report IoU mean \n",
    "    iou_val = np.mean(list_iou_val)\n",
    "    writer.add_scalar('iou_val/', np.mean(list_iou_val), 0)\n",
    "\n",
    "    return iou_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our objective Function\n",
    "This is the function we want to optimize given it's parameters. We want to find the parameters that will maximize accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(parameterization):\n",
    "    model = train(train_loader=dataloader_train, val_loader = dataloader_val, \n",
    "                  parameters=parameterization, dtype=torch.float, device=device)\n",
    "    return evaluate(\n",
    "        model=model,\n",
    "        val_loader=dataloader_val,\n",
    "        dtype=torch.float,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Bayesian Optimizer\n",
    "Search for best learning rate and momentum hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 06-02 17:32:23] ax.service.utils.dispatch: Using Bayesian Optimization generation strategy. Iterations after 5 will take longer to generate due to model-fitting.\n",
      "[INFO 06-02 17:32:23] ax.service.managed_loop: Started full optimization with 20 steps.\n",
      "[INFO 06-02 17:32:23] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 06-02 18:01:38] ax.service.managed_loop: Running optimization trial 2...\n",
      "[INFO 06-02 18:30:13] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 06-02 22:28:45] ax.service.managed_loop: Running optimization trial 11...\n"
     ]
    }
   ],
   "source": [
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-5, 1e-1], \"log_scale\": True},\n",
    "        {\"name\": \"bce_weight\", \"type\": \"range\", \"bounds\": [0.0, 1.0]},\n",
    "        {\"name\": \"iou_weight\", \"type\": \"range\", \"bounds\": [0.0, 1.0]},\n",
    "        {\"name\": \"dice_weight\", \"type\": \"range\", \"bounds\": [0.0, 1.0]},\n",
    "    ],\n",
    "    evaluation_function=objective_func,\n",
    "    objective_name='IoU',\n",
    "    total_trials=40, # Optional.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters:',best_parameters)\n",
    "print('IoU:', values)\n",
    "#render(plot_contour(model=model, param_x='lr', param_y='momentum', metric_name='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
